{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpMe\n",
    "import wandb\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as Datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "device = helpMe.get_default_device()\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CUNet_Lapgan_EMNIST\"\n",
    "image_size = 32\n",
    "batch_size = 64\n",
    "# z_dim = 128\n",
    "# DATA_DIR = './imageNet_lp/torch_image_folder/mnt/volume_sfo3_01/imagenet-lt/ImageDataset/train'\n",
    "# stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "channels =1\n",
    "epochs = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.Resize(32),\n",
    "    T.RandomRotation((-90,-90)),\n",
    "    T.RandomHorizontalFlip(1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "dataset = Datasets.EMNIST(root='./Datasxts/EMNIST/', split='byclass',train =True, download=True,transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset EMNIST\n",
       "    Number of datapoints: 697932\n",
       "    Root location: ./Datasxts/EMNIST/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=32, interpolation=bilinear, max_size=None, antialias=True)\n",
       "               RandomRotation(degrees=[-90.0, -90.0], interpolation=nearest, expand=False, fill=0)\n",
       "               RandomHorizontalFlip(p=1)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes= len(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/CUNet_Lapgan_EMNIST3/checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 3.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 358\u001b[0m\n\u001b[0;32m    354\u001b[0m discriminators \u001b[38;5;241m=\u001b[39m (disc32, disc16, disc8)\n\u001b[0;32m    356\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m3/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 358\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()  \u001b[38;5;66;03m# Finish the wandb run\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 147\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generators, discriminators, dataloader, num_epochs, batch_size, noise_dim, checkpoint_dir)\u001b[0m\n\u001b[0;32m    144\u001b[0m l1_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Initialize wandb\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLAPGAN_EMNIST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbetas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.999\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    155\u001b[0m     total_d32_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1163\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[1;32m-> 1163\u001b[0m     \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wi\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:189\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m _disable_service \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m settings_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m setup_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_disable_service\u001b[39m\u001b[38;5;124m\"\u001b[39m: _disable_service}\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl \u001b[38;5;241m=\u001b[39m \u001b[43mwandb_setup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msetup_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Make sure we have a logger setup (might be an early logger)\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_setup.py:327\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(settings)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\n\u001b[0;32m    325\u001b[0m     settings: Optional[Settings] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_WandbSetup\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 327\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_setup.py:320\u001b[0m, in \u001b[0;36m_setup\u001b[1;34m(settings, _reset)\u001b[0m\n\u001b[0;32m    318\u001b[0m     _WandbSetup\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m wl \u001b[38;5;241m=\u001b[39m \u001b[43m_WandbSetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wl\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_setup.py:303\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m    301\u001b[0m     _WandbSetup\u001b[38;5;241m.\u001b[39m_instance\u001b[38;5;241m.\u001b[39m_update(settings\u001b[38;5;241m=\u001b[39msettings)\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 303\u001b[0m _WandbSetup\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[43m_WandbSetup__WandbSetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_setup.py:114\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup.__init__\u001b[1;34m(self, pid, settings, environ)\u001b[0m\n\u001b[0;32m    111\u001b[0m wandb\u001b[38;5;241m.\u001b[39mtermsetup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings, logger)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check()\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m tracelog_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_tracelog\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracelog_mode:\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_setup.py:250\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     sweep_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39msweep_param_path\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sweep_path:\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_setup.py:277\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup_manager\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_disable_service:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager \u001b[38;5;241m=\u001b[39m \u001b[43mwandb_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\wandb_manager.py:139\u001b[0m, in \u001b[0;36m_Manager.__init__\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m    137\u001b[0m token \u001b[38;5;241m=\u001b[39m _ManagerToken\u001b[38;5;241m.\u001b[39mfrom_environment()\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     host \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtcp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\service\\service.py:253\u001b[0m, in \u001b[0;36m_Service.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\service\\service.py:245\u001b[0m, in \u001b[0;36m_Service._launch_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_startup_debug_print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_ports\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_ports\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_proc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    247\u001b[0m     _sentry\u001b[38;5;241m.\u001b[39mreraise(e)\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\wandb\\sdk\\service\\service.py:118\u001b[0m, in \u001b[0;36m_Service._wait_for_ports\u001b[1;34m(self, fname, proc)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceStartProcessError(\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb service process exited with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproc\u001b[38;5;241m.\u001b[39mreturncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsure that `sys.executable` is a valid python interpreter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(fname):\n\u001b[1;32m--> 118\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import wandb  # Import wandb\n",
    "\n",
    "# Ensure you have all necessary imports for your UNet and Discriminator models\n",
    "import Unet  # Assuming you have a file named Unet.py with relevant model definitions\n",
    "\n",
    "# # Initialize gradient scalers for mixed precision training\n",
    "# scaler_G_32 = GradScaler()\n",
    "# scaler_G_16 = GradScaler()\n",
    "# scaler_G_8 = GradScaler()\n",
    "# scaler_D_32 = GradScaler()\n",
    "# scaler_D_16 = GradScaler()\n",
    "# scaler_D_8 = GradScaler()\n",
    "\n",
    "class LAPGAN(nn.Module):\n",
    "    def __init__(self, generators, save_path):\n",
    "        super(LAPGAN, self).__init__()\n",
    "        self.G_32, self.G_16, self.G_8 = generators\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def forward(self, z, y, epoch, i):\n",
    "        # Generate the smallest scale image (8x8)\n",
    "        x = self.G_8(z, y)\n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='8_before', a='LAPgan/')\n",
    "        # wandb.log({\"Generated Images\": [wandb.Image(fake_images, caption=f\"Epoch {epoch}\")]})\n",
    "        self.log_generated_images(x, epoch, i, res='8_before')\n",
    "\n",
    "        # Upscale to 16x16\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='8_after', a='LAPgan/')   \n",
    "        self.log_generated_images(x, epoch, i, res='8_after')\n",
    "\n",
    "        # Refine with next generator\n",
    "        xH = self.G_16(x, y)\n",
    "        x = x + xH\n",
    "        \n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='16', a='LAPgan/')\n",
    "        self.log_generated_images(x, epoch, i, res='16')\n",
    "        \n",
    "\n",
    "        # Upscale to 32x32\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "\n",
    "        # Refine with the final generator\n",
    "        xH = self.G_32(x, y)\n",
    "        x = x + xH\n",
    "        \n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='32', a='LAPgan/')\n",
    "        self.log_generated_images(x, epoch, i, res='32')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def log_generated_images(self, images, epoch, i, res):\n",
    "        images_cpu = images.detach().cpu()\n",
    "        grid = torchvision.utils.make_grid(images_cpu, normalize=True, scale_each=True, nrow=8)\n",
    "        wandb.log({f\"Generated Images {res}\": [wandb.Image(grid, caption=f\"Epoch: {epoch}\")]})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "def save_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, epoch, checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'G_32_state_dict': generators[0].state_dict(),\n",
    "        'D_32_state_dict': discriminators[0].state_dict(),\n",
    "        'G_16_state_dict': generators[1].state_dict(),\n",
    "        'D_16_state_dict': discriminators[1].state_dict(),\n",
    "        'G_8_state_dict': generators[2].state_dict(),\n",
    "        'D_8_state_dict': discriminators[2].state_dict(),\n",
    "        'opt_G_32_state_dict': opt_G_32.state_dict(),\n",
    "        'opt_D_32_state_dict': opt_D_32.state_dict(),\n",
    "        'opt_G_16_state_dict': opt_G_16.state_dict(),\n",
    "        'opt_D_16_state_dict': opt_D_16.state_dict(),\n",
    "        'opt_G_8_state_dict': opt_G_8.state_dict(),\n",
    "        'opt_D_8_state_dict': opt_D_8.state_dict()\n",
    "    }, checkpoint_path)\n",
    "\n",
    "def load_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, checkpoint_dir, device):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pth')\n",
    "    print(checkpoint_path)\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        generators[0].load_state_dict(checkpoint['G_32_state_dict'])\n",
    "        discriminators[0].load_state_dict(checkpoint['D_32_state_dict'])\n",
    "        generators[1].load_state_dict(checkpoint['G_16_state_dict'])\n",
    "        discriminators[1].load_state_dict(checkpoint['D_16_state_dict'])\n",
    "        generators[2].load_state_dict(checkpoint['G_8_state_dict'])\n",
    "        discriminators[2].load_state_dict(checkpoint['D_8_state_dict'])\n",
    "        opt_G_32.load_state_dict(checkpoint['opt_G_32_state_dict'])\n",
    "        opt_D_32.load_state_dict(checkpoint['opt_D_32_state_dict'])\n",
    "        opt_G_16.load_state_dict(checkpoint['opt_G_16_state_dict'])\n",
    "        opt_D_16.load_state_dict(checkpoint['opt_D_16_state_dict'])\n",
    "        opt_G_8.load_state_dict(checkpoint['opt_G_8_state_dict'])\n",
    "        opt_D_8.load_state_dict(checkpoint['opt_D_8_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "        print(\"Starting training from scratch.\")\n",
    "    return start_epoch\n",
    "\n",
    "\n",
    "def train_gan(generators, discriminators, dataloader, num_epochs, batch_size, noise_dim=100, checkpoint_dir=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = 'cpu'\n",
    "    G_32, G_16, G_8 = [gen.to(device) for gen in generators]\n",
    "    D_32, D_16, D_8 = [disc.to(device) for disc in discriminators]\n",
    "\n",
    "    # Optimizers\n",
    "    opt_G_32 = optim.Adam(G_32.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_D_32 = optim.Adam(D_32.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_G_16 = optim.Adam(G_16.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_D_16 = optim.Adam(D_16.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_G_8 = optim.Adam(G_8.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_D_8 = optim.Adam(D_8.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    if checkpoint_dir:\n",
    "        start_epoch = load_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, checkpoint_dir, device)\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "\n",
    "    # Loss functions\n",
    "    criterion = nn.BCELoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=\"LAPGAN_EMNIST\", config={\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"betas\": (0.5, 0.999)\n",
    "    })\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        total_d32_loss = 0.0\n",
    "        total_g32_loss = 0.0\n",
    "        total_d16_loss = 0.0\n",
    "        total_g16_loss = 0.0\n",
    "        total_d8_loss = 0.0\n",
    "        total_g8_loss = 0.0\n",
    "\n",
    "        with tqdm(enumerate(dataloader), total=len(dataloader)) as t:\n",
    "            for i, (images, labels) in t:\n",
    "                images_8 = F.interpolate(images, scale_factor=0.25, mode='bilinear')\n",
    "\n",
    "                # for j in range(5):\n",
    "                # perm = torch.randperm(images_8.size(0))\n",
    "                images_8 = images_8\n",
    "                labels = labels\n",
    "\n",
    "                real = images_8.to(device)\n",
    "                labels = labels.to(device)\n",
    "                noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "                fake = G_8(noise, labels)\n",
    "\n",
    "                # Train Discriminator(D_8)\n",
    "                D_8_real = D_8(real, labels).view(-1)\n",
    "                loss_D_8_real = criterion(D_8_real, torch.ones_like(D_8_real))\n",
    "                D_8_fake = D_8(fake.detach(), labels).view(-1)\n",
    "                loss_D_8_fake = criterion(D_8_fake, torch.zeros_like(D_8_fake))\n",
    "                loss_D_8 = (loss_D_8_real + loss_D_8_fake) / 2\n",
    "                opt_D_8.zero_grad()\n",
    "                loss_D_8.backward()\n",
    "                opt_D_8.step()\n",
    "\n",
    "                total_d8_loss += loss_D_8.item()\n",
    "\n",
    "                # Train Generator for 8x8 images\n",
    "                output = D_8(fake, labels).view(-1)\n",
    "                loss_G_8 = criterion(output, torch.ones_like(output))\n",
    "\n",
    "                opt_G_8.zero_grad()\n",
    "                loss_G_8.backward()\n",
    "                opt_G_8.step()\n",
    "\n",
    "                total_g8_loss += loss_G_8.item()\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    helpMe.save_generated_images(genH_realH=torch.cat([real, fake], dim=0), recon=None, epoch=epoch, i=i,\n",
    "                                                 path=checkpoint_dir, res='8', a='')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                images_G8 = F.interpolate(fake, scale_factor=2, mode='bilinear').detach()\n",
    "                \n",
    "                del images_8, noise, fake, D_8_real, D_8_fake, loss_D_8_real, loss_D_8_fake, output\n",
    "                \n",
    "                images_16 = F.interpolate(images, scale_factor=0.5, mode='bilinear')\n",
    "                _, real_high_freqs = helpMe.to_gaus(imgs=images_16)\n",
    "                real_high_freqs = real_high_freqs.to(device)\n",
    "\n",
    "                # Train Discriminator(D_16)\n",
    "                opt_D_16.zero_grad()\n",
    "                output_real_16 = D_16(real_high_freqs, labels).view(-1)\n",
    "                loss_disc_real_16 = criterion(output_real_16, torch.ones_like(output_real_16))\n",
    "                generated_high_freqs_16 = G_16(images_G8, labels)\n",
    "                output_fake_16 = D_16(generated_high_freqs_16.detach(), labels).view(-1)\n",
    "                loss_disc_fake_16 = criterion(output_fake_16, torch.zeros_like(output_fake_16))\n",
    "                loss_disc_16 = (loss_disc_real_16 + loss_disc_fake_16) / 2\n",
    "                loss_disc_16.backward()\n",
    "                opt_D_16.step()\n",
    "\n",
    "                total_d16_loss += loss_disc_16.item()\n",
    "\n",
    "                # Train Generator for 16x16 images\n",
    "                opt_G_16.zero_grad()\n",
    "                \n",
    "                # generated_high_freqs_16_1 = G_16(images_G8)\n",
    "                output_fake_16 = D_16(generated_high_freqs_16, labels).view(-1)\n",
    "                adv_loss_16 = criterion(output_fake_16, torch.ones_like(output_fake_16))\n",
    "                l1_loss_16 = l1_loss(generated_high_freqs_16, real_high_freqs)\n",
    "                loss_gen_16 = adv_loss_16 \n",
    "                loss_gen_16.backward()\n",
    "                \n",
    "                opt_G_16.step()\n",
    "\n",
    "                total_g16_loss += loss_gen_16.item()\n",
    "\n",
    "                recon_imgs = images_G8 + generated_high_freqs_16\n",
    "                if i % 100 == 0:\n",
    "                    helpMe.save_generated_images(genH_realH=torch.cat([real_high_freqs, generated_high_freqs_16], dim=0),\n",
    "                                                 recon=torch.cat([images_G8, recon_imgs], dim=0), epoch=epoch, i=i,\n",
    "                                                 path=checkpoint_dir, res='16', a='')\n",
    "                \n",
    "                \n",
    "                \n",
    "                images_G16 = F.interpolate(recon_imgs, scale_factor=2, mode='bilinear').detach()\n",
    "                del images_16, real_high_freqs, generated_high_freqs_16, output_real_16, output_fake_16, loss_disc_real_16, loss_disc_fake_16, adv_loss_16, l1_loss_16, recon_imgs\n",
    "               \n",
    "               \n",
    "                _, real_high_freqs = helpMe.to_gaus(imgs=images)\n",
    "                real_high_freqs = real_high_freqs.to(device)\n",
    "                \n",
    "                \n",
    "\n",
    "                # Train Discriminator (D_32)\n",
    "                opt_D_32.zero_grad()\n",
    "                output_real_32 = D_32(real_high_freqs, labels).view(-1)\n",
    "                loss_disc_real_32 = criterion(output_real_32, torch.ones_like(output_real_32))\n",
    "                generated_high_freqs_32 = G_32(images_G16, labels)\n",
    "                output_fake_32 = D_32(generated_high_freqs_32.detach(), labels).view(-1)\n",
    "                loss_disc_fake_32 = criterion(output_fake_32, torch.zeros_like(output_fake_32))\n",
    "                loss_disc_32 = (loss_disc_real_32 + loss_disc_fake_32) / 2\n",
    "                loss_disc_32.backward(retain_graph=True)\n",
    "                opt_D_32.step()\n",
    "\n",
    "                total_d32_loss += loss_disc_32.item()\n",
    "\n",
    "                # Train Generator for 32x32 images\n",
    "                opt_G_32.zero_grad()\n",
    "                output_fake_32 = D_32(generated_high_freqs_32, labels).view(-1)\n",
    "                adv_loss_32 = criterion(output_fake_32, torch.ones_like(output_fake_32))\n",
    "                l1_loss_32 = l1_loss(generated_high_freqs_32, real_high_freqs)\n",
    "                loss_gen_32 = adv_loss_32 \n",
    "                loss_gen_32.backward()\n",
    "                opt_G_32.step()\n",
    "\n",
    "                total_g32_loss += loss_gen_32.item()\n",
    "\n",
    "                recon_imgs = images_G16 + generated_high_freqs_32\n",
    "                if i % 100 == 0:\n",
    "                    helpMe.save_generated_images(genH_realH=torch.cat([real_high_freqs, generated_high_freqs_32], dim=0),\n",
    "                                                 recon=torch.cat([images_G16, recon_imgs], dim=0), epoch=epoch, i=i,\n",
    "                                                 path=checkpoint_dir, res='32', a='')\n",
    "                    \n",
    "                del images, labels, real_high_freqs, generated_high_freqs_32, output_real_32, output_fake_32, loss_disc_real_32, loss_disc_fake_32, adv_loss_32, l1_loss_32, recon_imgs\n",
    "                \n",
    "                \n",
    "                t.set_description(f'Epoch [{epoch}/{num_epochs}]')\n",
    "                t.set_postfix({\n",
    "                    'D32_loss': f'{loss_disc_32:.3f}',\n",
    "                    'G32_loss': f'{loss_gen_32:.3f}',\n",
    "                    'D16_loss': f'{loss_disc_16:.3f}',\n",
    "                    'G16_loss': f'{loss_gen_16:.3f}',\n",
    "                    'D8_loss': f'{loss_D_8:.3f}',\n",
    "                    'G8_loss': f'{loss_G_8:.3f}'\n",
    "                })\n",
    "\n",
    "                wandb.log({\n",
    "                    'D32_loss': loss_disc_32.item(),\n",
    "                    'G32_loss': loss_gen_32.item(),\n",
    "                    'D16_loss': loss_disc_16.item(),\n",
    "                    'G16_loss': loss_gen_16.item(),\n",
    "                    'D8_loss': loss_D_8.item(),\n",
    "                    'G8_loss': loss_G_8.item()\n",
    "                })\n",
    "                \n",
    "                \n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "\n",
    "        avg_d32_loss = total_d32_loss / len(dataloader)\n",
    "        avg_g32_loss = total_g32_loss / len(dataloader)\n",
    "        avg_d16_loss = total_d16_loss / len(dataloader)\n",
    "        avg_g16_loss = total_g16_loss / len(dataloader)\n",
    "        avg_d8_loss = total_d8_loss / (len(dataloader)*5)\n",
    "        avg_g8_loss = total_g8_loss / (len(dataloader)*5)\n",
    "        print(f\"Epoch {epoch}: Loss D32: {avg_d32_loss:.4f}, Loss G32: {avg_g32_loss:.4f}, Loss D16: {avg_d16_loss:.4f}, Loss G16: {avg_g16_loss:.4f}, Loss D8: {avg_d8_loss:.4f}, Loss G8: {avg_g8_loss:.4f}\")\n",
    "\n",
    "        # save_path = 'path/to/save/images'\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # device = 'cpu'\n",
    "        lapgan_model = LAPGAN(generators, checkpoint_dir)\n",
    "        lapgan_model.to(device)\n",
    "\n",
    "        \n",
    "        fixed_noise = torch.randn(num_classes, noise_dim, device=device)\n",
    "        fixed_labels = torch.arange(0, num_classes, dtype=torch.long, device=device)\n",
    "        # noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "        lapgan_model(fixed_noise, fixed_labels, epoch, i)\n",
    "\n",
    "        save_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, epoch, checkpoint_dir)\n",
    "\n",
    "# Assuming dataset and other parameters are properly defined elsewhere\n",
    "gen32 = Unet.CUNetGenerator(num_classes = num_classes)\n",
    "disc32 = Unet.CDiscriminator(num_classes = num_classes)\n",
    "gen16 = Unet.CUNetGenerator(image_size = 16, features=[64, 128, 256],num_classes = num_classes)\n",
    "disc16 = Unet.CDiscriminator(image_size = 16, features=[64, 128, 256], num_classes = num_classes)\n",
    "gen8 = Unet.Generator_L(num_classes=num_classes)\n",
    "disc8 = Unet.Discriminator_L(num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "generators = (gen32, gen16, gen8)\n",
    "discriminators = (disc32, disc16, disc8)\n",
    "\n",
    "checkpoint_dir = f\"Models/{model_name}3/\"\n",
    "\n",
    "train_gan(generators, discriminators, dataloader, num_epochs=epochs, batch_size=batch_size, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "wandb.finish()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
