{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpMe\n",
    "import wandb\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as Datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = helpMe.get_default_device()\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"UNet_Lapgan\"\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "# z_dim = 128\n",
    "# DATA_DIR = './imageNet_lp/torch_image_folder/mnt/volume_sfo3_01/imagenet-lt/ImageDataset/train'\n",
    "# stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "channels =1\n",
    "epochs = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms = T.Compose([\n",
    "    T.Resize(32),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "dataset = Datasets.CIFAR10(root='./Datasxts/CIFAR10/', train=True, download=True,transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create GEN AND DISC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               if i % 100 == 0:\n",
    "                    recon_imgs = smoothed_images + generated_high_freqs\n",
    "                    helpMe.save_generated_images(torch.cat([real_high_freqs,generated_high_freqs],dim=0),torch.cat([images.to(device),recon_imgs],dim=0), epoch,i, checkpoint_dir, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/UNet_Lapgan3/checkpoint.pth\n",
      "Starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maruntd008\u001b[0m (\u001b[33maruntd08\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b2634ac05746efa84d6a50785eefd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Arun\\pytorch\\expriements\\LAPGAN\\wandb\\run-20240601_020106-70yln7cd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruntd08/LapGAN/runs/70yln7cd' target=\"_blank\">distinctive-sound-51</a></strong> to <a href='https://wandb.ai/aruntd08/LapGAN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruntd08/LapGAN' target=\"_blank\">https://wandb.ai/aruntd08/LapGAN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruntd08/LapGAN/runs/70yln7cd' target=\"_blank\">https://wandb.ai/aruntd08/LapGAN/runs/70yln7cd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/110]: 100%|██████████| 1562/1562 [04:19<00:00,  6.03it/s, D32_loss=0.731, G32_loss=1.404, D16_loss=0.696, G16_loss=1.243, D8_loss=0.446, G8_loss=1.510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss D32: 0.6370, Loss G32: 2.0579, Loss D16: 0.6833, Loss G16: 1.4286, Loss D8: 0.3986, Loss G8: 2.1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/110]: 100%|██████████| 1562/1562 [06:33<00:00,  3.97it/s, D32_loss=0.665, G32_loss=1.703, D16_loss=0.687, G16_loss=1.232, D8_loss=0.606, G8_loss=1.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss D32: 0.6654, Loss G32: 1.5306, Loss D16: 0.6940, Loss G16: 1.2358, Loss D8: 0.5618, Loss G8: 1.2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/110]:   3%|▎         | 48/1562 [00:14<07:09,  3.53it/s, D32_loss=0.663, G32_loss=1.812, D16_loss=0.704, G16_loss=1.207, D8_loss=0.583, G8_loss=1.091]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:20.540463, resuming normal operation.\n",
      "Epoch [3/110]: 100%|██████████| 1562/1562 [07:31<00:00,  3.46it/s, D32_loss=0.587, G32_loss=2.019, D16_loss=0.670, G16_loss=1.339, D8_loss=0.607, G8_loss=0.954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss D32: 0.6106, Loss G32: 1.8752, Loss D16: 0.6913, Loss G16: 1.2542, Loss D8: 0.6197, Loss G8: 0.9963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/110]: 100%|██████████| 1562/1562 [06:17<00:00,  4.13it/s, D32_loss=0.404, G32_loss=2.057, D16_loss=0.728, G16_loss=1.237, D8_loss=0.600, G8_loss=0.910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss D32: 0.5930, Loss G32: 1.9882, Loss D16: 0.6913, Loss G16: 1.2579, Loss D8: 0.6353, Loss G8: 0.9441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/110]: 100%|██████████| 1562/1562 [03:53<00:00,  6.69it/s, D32_loss=0.441, G32_loss=2.305, D16_loss=0.728, G16_loss=1.230, D8_loss=0.643, G8_loss=0.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss D32: 0.5821, Loss G32: 2.0135, Loss D16: 0.6888, Loss G16: 1.2672, Loss D8: 0.6484, Loss G8: 0.8973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/110]: 100%|██████████| 1562/1562 [03:51<00:00,  6.74it/s, D32_loss=0.657, G32_loss=2.018, D16_loss=0.696, G16_loss=1.293, D8_loss=0.614, G8_loss=0.852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss D32: 0.6034, Loss G32: 1.9114, Loss D16: 0.6848, Loss G16: 1.2868, Loss D8: 0.6586, Loss G8: 0.8573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/110]: 100%|██████████| 1562/1562 [06:17<00:00,  4.14it/s, D32_loss=0.692, G32_loss=1.740, D16_loss=0.646, G16_loss=1.312, D8_loss=0.638, G8_loss=0.805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss D32: 0.5520, Loss G32: 2.1284, Loss D16: 0.6800, Loss G16: 1.3043, Loss D8: 0.6656, Loss G8: 0.8320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/110]:   2%|▏         | 39/1562 [00:12<07:54,  3.21it/s, D32_loss=0.556, G32_loss=2.236, D16_loss=0.704, G16_loss=1.316, D8_loss=0.681, G8_loss=0.769]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.483126, resuming normal operation.\n",
      "Epoch [8/110]: 100%|██████████| 1562/1562 [06:28<00:00,  4.02it/s, D32_loss=0.524, G32_loss=2.183, D16_loss=0.661, G16_loss=1.327, D8_loss=0.646, G8_loss=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss D32: 0.5670, Loss G32: 2.1514, Loss D16: 0.6836, Loss G16: 1.2957, Loss D8: 0.6690, Loss G8: 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/110]:   5%|▍         | 74/1562 [00:13<07:03,  3.51it/s, D32_loss=0.523, G32_loss=2.187, D16_loss=0.673, G16_loss=1.295, D8_loss=0.686, G8_loss=0.756]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.286607, resuming normal operation.\n",
      "Epoch [9/110]: 100%|██████████| 1562/1562 [07:22<00:00,  3.53it/s, D32_loss=0.303, G32_loss=3.015, D16_loss=0.682, G16_loss=1.298, D8_loss=0.638, G8_loss=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss D32: 0.5348, Loss G32: 2.2392, Loss D16: 0.6793, Loss G16: 1.3120, Loss D8: 0.6712, Loss G8: 0.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/110]:   1%|          | 9/1562 [00:02<07:17,  3.55it/s, D32_loss=0.382, G32_loss=2.405, D16_loss=0.666, G16_loss=1.336, D8_loss=0.707, G8_loss=0.795]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.467540, resuming normal operation.\n",
      "Epoch [10/110]: 100%|██████████| 1562/1562 [07:28<00:00,  3.48it/s, D32_loss=0.703, G32_loss=2.039, D16_loss=0.706, G16_loss=1.312, D8_loss=0.681, G8_loss=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss D32: 0.4715, Loss G32: 2.5885, Loss D16: 0.6725, Loss G16: 1.3318, Loss D8: 0.6729, Loss G8: 0.8052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/110]:   0%|          | 4/1562 [00:01<09:17,  2.79it/s, D32_loss=0.157, G32_loss=2.834, D16_loss=0.685, G16_loss=1.287, D8_loss=0.668, G8_loss=0.788]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:20.916872, resuming normal operation.\n",
      "Epoch [11/110]: 100%|██████████| 1562/1562 [07:32<00:00,  3.45it/s, D32_loss=0.647, G32_loss=2.406, D16_loss=0.685, G16_loss=1.289, D8_loss=0.642, G8_loss=0.790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss D32: 0.4765, Loss G32: 2.6049, Loss D16: 0.6773, Loss G16: 1.3227, Loss D8: 0.6763, Loss G8: 0.7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/110]:   2%|▏         | 28/1562 [00:08<07:22,  3.47it/s, D32_loss=0.591, G32_loss=2.419, D16_loss=0.676, G16_loss=1.257, D8_loss=0.629, G8_loss=0.839]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.635574, resuming normal operation.\n",
      "Epoch [12/110]: 100%|██████████| 1562/1562 [05:19<00:00,  4.89it/s, D32_loss=0.702, G32_loss=2.230, D16_loss=0.710, G16_loss=1.285, D8_loss=0.671, G8_loss=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss D32: 0.4795, Loss G32: 2.6018, Loss D16: 0.6756, Loss G16: 1.3296, Loss D8: 0.6782, Loss G8: 0.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/110]: 100%|██████████| 1562/1562 [04:58<00:00,  5.23it/s, D32_loss=0.239, G32_loss=3.167, D16_loss=0.709, G16_loss=1.304, D8_loss=0.687, G8_loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss D32: 0.4173, Loss G32: 3.0238, Loss D16: 0.6692, Loss G16: 1.3528, Loss D8: 0.6813, Loss G8: 0.7678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/110]: 100%|██████████| 1562/1562 [06:05<00:00,  4.27it/s, D32_loss=0.268, G32_loss=3.712, D16_loss=0.638, G16_loss=1.450, D8_loss=0.683, G8_loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss D32: 0.4111, Loss G32: 3.1145, Loss D16: 0.6699, Loss G16: 1.3532, Loss D8: 0.6815, Loss G8: 0.7685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 397\u001b[0m\n\u001b[0;32m    393\u001b[0m discriminators \u001b[38;5;241m=\u001b[39m (disc32, disc16, disc8)\n\u001b[0;32m    395\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m3/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 397\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()  \u001b[38;5;66;03m# Finish the wandb run\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 380\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generators, discriminators, dataloader, num_epochs, batch_size, noise_dim, checkpoint_dir)\u001b[0m\n\u001b[0;32m    377\u001b[0m lapgan_model(fixed_noise, fixed_labels, epoch, i)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_G_32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_D_32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_G_16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_D_16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_G_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_D_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 123\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, epoch, checkpoint_dir)\u001b[0m\n\u001b[0;32m    121\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(checkpoint_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    122\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 123\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG_32_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD_32_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG_16_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD_16_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG_8_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD_8_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopt_G_32_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_G_32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopt_D_32_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_D_32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopt_G_16_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_G_16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopt_D_16_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_D_16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopt_G_8_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_G_8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopt_D_8_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_D_8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\py_torch\\Lib\\site-packages\\torch\\serialization.py:629\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 629\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Arun\\anaconda3\\envs\\py_torch\\Lib\\site-packages\\torch\\serialization.py:863\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[0;32m    862\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[1;32m--> 863\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(name, storage\u001b[38;5;241m.\u001b[39mdata_ptr(), num_bytes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.775047, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import wandb  # Import wandb\n",
    "\n",
    "# Ensure you have all necessary imports for your UNet and Discriminator models\n",
    "import Unet  # Assuming you have a file named Unet.py with relevant model definitions\n",
    "\n",
    "# # Initialize gradient scalers for mixed precision training\n",
    "# scaler_G_32 = GradScaler()\n",
    "# scaler_G_16 = GradScaler()\n",
    "# scaler_G_8 = GradScaler()\n",
    "# scaler_D_32 = GradScaler()\n",
    "# scaler_D_16 = GradScaler()\n",
    "# scaler_D_8 = GradScaler()\n",
    "\n",
    "class LAPGAN(nn.Module):\n",
    "    def __init__(self, generators, discriminators, save_path, device):\n",
    "        super(LAPGAN, self).__init__()\n",
    "        self.G_32, self.G_16, self.G_8 = generators\n",
    "        self.save_path = save_path\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, z, y, epoch, i):\n",
    "        # Generate the smallest scale image (8x8)\n",
    "        x = self.G_8(z, y)\n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='8_before', a='LAPgan/')\n",
    "        # wandb.log({\"Generated Images\": [wandb.Image(fake_images, caption=f\"Epoch {epoch}\")]})\n",
    "        self.log_generated_images(x, epoch, i, res='8_before')\n",
    "\n",
    "        # Upscale to 16x16\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='8_after', a='LAPgan/')   \n",
    "        self.log_generated_images(x, epoch, i, res='8_after')\n",
    "\n",
    "        # Refine with next generator\n",
    "        xH = self.G_16(x)\n",
    "        x = x + xH\n",
    "        \n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='16', a='LAPgan/')\n",
    "        self.log_generated_images(x, epoch, i, res='16')\n",
    "        \n",
    "\n",
    "        # Upscale to 32x32\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "\n",
    "        # Refine with the final generator\n",
    "        xH = self.G_32(x)\n",
    "        x = x + xH\n",
    "        \n",
    "        helpMe.save_generated_images(genH_realH=x,recon=None, epoch=epoch, i=i, path=self.save_path,res='32', a='LAPgan/')\n",
    "        self.log_generated_images(x, epoch, i, res='32')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def log_generated_images(self, images, epoch, i, res):\n",
    "        images_cpu = images.detach().cpu()\n",
    "        grid = torchvision.utils.make_grid(images_cpu, normalize=True, scale_each=True, nrow=8)\n",
    "        wandb.log({f\"Generated Images {res}\": [wandb.Image(grid, caption=f\"Epoch: {epoch}\")]})\n",
    "\n",
    "\n",
    "\n",
    "def load_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, checkpoint_dir, device):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pth')\n",
    "    print(checkpoint_path)\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        generators[0].load_state_dict(checkpoint['G_32_state_dict'])\n",
    "        discriminators[0].load_state_dict(checkpoint['D_32_state_dict'])\n",
    "        generators[1].load_state_dict(checkpoint['G_16_state_dict'])\n",
    "        discriminators[1].load_state_dict(checkpoint['D_16_state_dict'])\n",
    "        generators[2].load_state_dict(checkpoint['G_8_state_dict'])\n",
    "        discriminators[2].load_state_dict(checkpoint['D_8_state_dict'])\n",
    "        opt_G_32.load_state_dict(checkpoint['opt_G_32_state_dict'])\n",
    "        opt_D_32.load_state_dict(checkpoint['opt_D_32_state_dict'])\n",
    "        opt_G_16.load_state_dict(checkpoint['opt_G_16_state_dict'])\n",
    "        opt_D_16.load_state_dict(checkpoint['opt_D_16_state_dict'])\n",
    "        opt_G_8.load_state_dict(checkpoint['opt_G_8_state_dict'])\n",
    "        opt_D_8.load_state_dict(checkpoint['opt_D_8_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "        print(\"Starting training from scratch.\")\n",
    "    return start_epoch\n",
    "\n",
    "def save_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, epoch, checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'G_32_state_dict': generators[0].state_dict(),\n",
    "        'D_32_state_dict': discriminators[0].state_dict(),\n",
    "        'G_16_state_dict': generators[1].state_dict(),\n",
    "        'D_16_state_dict': discriminators[1].state_dict(),\n",
    "        'G_8_state_dict': generators[2].state_dict(),\n",
    "        'D_8_state_dict': discriminators[2].state_dict(),\n",
    "        'opt_G_32_state_dict': opt_G_32.state_dict(),\n",
    "        'opt_D_32_state_dict': opt_D_32.state_dict(),\n",
    "        'opt_G_16_state_dict': opt_G_16.state_dict(),\n",
    "        'opt_D_16_state_dict': opt_D_16.state_dict(),\n",
    "        'opt_G_8_state_dict': opt_G_8.state_dict(),\n",
    "        'opt_D_8_state_dict': opt_D_8.state_dict()\n",
    "    }, checkpoint_path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "def save_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, epoch, checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'G_32_state_dict': generators[0].state_dict(),\n",
    "        'D_32_state_dict': discriminators[0].state_dict(),\n",
    "        'G_16_state_dict': generators[1].state_dict(),\n",
    "        'D_16_state_dict': discriminators[1].state_dict(),\n",
    "        'G_8_state_dict': generators[2].state_dict(),\n",
    "        'D_8_state_dict': discriminators[2].state_dict(),\n",
    "        'opt_G_32_state_dict': opt_G_32.state_dict(),\n",
    "        'opt_D_32_state_dict': opt_D_32.state_dict(),\n",
    "        'opt_G_16_state_dict': opt_G_16.state_dict(),\n",
    "        'opt_D_16_state_dict': opt_D_16.state_dict(),\n",
    "        'opt_G_8_state_dict': opt_G_8.state_dict(),\n",
    "        'opt_D_8_state_dict': opt_D_8.state_dict()\n",
    "    }, checkpoint_path)\n",
    "\n",
    "def load_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, checkpoint_dir, device):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pth')\n",
    "    print(checkpoint_path)\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        generators[0].load_state_dict(checkpoint['G_32_state_dict'])\n",
    "        discriminators[0].load_state_dict(checkpoint['D_32_state_dict'])\n",
    "        generators[1].load_state_dict(checkpoint['G_16_state_dict'])\n",
    "        discriminators[1].load_state_dict(checkpoint['D_16_state_dict'])\n",
    "        generators[2].load_state_dict(checkpoint['G_8_state_dict'])\n",
    "        discriminators[2].load_state_dict(checkpoint['D_8_state_dict'])\n",
    "        opt_G_32.load_state_dict(checkpoint['opt_G_32_state_dict'])\n",
    "        opt_D_32.load_state_dict(checkpoint['opt_D_32_state_dict'])\n",
    "        opt_G_16.load_state_dict(checkpoint['opt_G_16_state_dict'])\n",
    "        opt_D_16.load_state_dict(checkpoint['opt_D_16_state_dict'])\n",
    "        opt_G_8.load_state_dict(checkpoint['opt_G_8_state_dict'])\n",
    "        opt_D_8.load_state_dict(checkpoint['opt_D_8_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "        print(\"Starting training from scratch.\")\n",
    "    return start_epoch\n",
    "\n",
    "\n",
    "def train_gan(generators, discriminators, dataloader, num_epochs, batch_size, noise_dim=100, checkpoint_dir=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = 'cpu'\n",
    "    G_32, G_16, G_8 = [gen.to(device) for gen in generators]\n",
    "    D_32, D_16, D_8 = [disc.to(device) for disc in discriminators]\n",
    "\n",
    "    # Optimizers\n",
    "    opt_G_32 = optim.Adam(G_32.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_D_32 = optim.Adam(D_32.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_G_16 = optim.Adam(G_16.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_D_16 = optim.Adam(D_16.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_G_8 = optim.Adam(G_8.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    opt_D_8 = optim.Adam(D_8.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    if checkpoint_dir:\n",
    "        start_epoch = load_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, checkpoint_dir, device)\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "\n",
    "    # Loss functions\n",
    "    criterion = nn.BCELoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=\"LAPGAN\", config={\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"betas\": (0.5, 0.999)\n",
    "    })\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        total_d32_loss = 0.0\n",
    "        total_g32_loss = 0.0\n",
    "        total_d16_loss = 0.0\n",
    "        total_g16_loss = 0.0\n",
    "        total_d8_loss = 0.0\n",
    "        total_g8_loss = 0.0\n",
    "\n",
    "        with tqdm(enumerate(dataloader), total=len(dataloader)) as t:\n",
    "            for i, (images, labels) in t:\n",
    "                images_8 = F.interpolate(images, scale_factor=0.25, mode='bilinear')\n",
    "\n",
    "                for j in range(5):\n",
    "                    perm = torch.randperm(images_8.size(0))\n",
    "                    images_8 = images_8[perm]\n",
    "                    labels = labels[perm]\n",
    "\n",
    "                    real = images_8.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "                    fake = G_8(noise, labels)\n",
    "\n",
    "                    # Train Discriminator(D_8)\n",
    "                    D_8_real = D_8(real, labels).view(-1)\n",
    "                    loss_D_8_real = criterion(D_8_real, torch.ones_like(D_8_real))\n",
    "                    D_8_fake = D_8(fake.detach(), labels).view(-1)\n",
    "                    loss_D_8_fake = criterion(D_8_fake, torch.zeros_like(D_8_fake))\n",
    "                    loss_D_8 = (loss_D_8_real + loss_D_8_fake) / 2\n",
    "                    opt_D_8.zero_grad()\n",
    "                    loss_D_8.backward()\n",
    "                    opt_D_8.step()\n",
    "\n",
    "                    total_d8_loss += loss_D_8.item()\n",
    "\n",
    "                    # Train Generator for 8x8 images\n",
    "                    output = D_8(fake, labels).view(-1)\n",
    "                    loss_G_8 = criterion(output, torch.ones_like(output))\n",
    "\n",
    "                    opt_G_8.zero_grad()\n",
    "                    loss_G_8.backward()\n",
    "                    opt_G_8.step()\n",
    "\n",
    "                    total_g8_loss += loss_G_8.item()\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    helpMe.save_generated_images(genH_realH=torch.cat([real, fake], dim=0), recon=None, epoch=epoch, i=i,\n",
    "                                                 path=checkpoint_dir, res='8', a='')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                images_G8 = F.interpolate(fake, scale_factor=2, mode='bilinear').detach()\n",
    "                \n",
    "                del images_8, labels, noise, fake, D_8_real, D_8_fake, loss_D_8_real, loss_D_8_fake, output\n",
    "                \n",
    "                images_16 = F.interpolate(images, scale_factor=0.5, mode='bilinear')[perm]\n",
    "                _, real_high_freqs = helpMe.to_gaus(imgs=images_16)\n",
    "                real_high_freqs = real_high_freqs.to(device)\n",
    "\n",
    "                # Train Discriminator(D_16)\n",
    "                opt_D_16.zero_grad()\n",
    "                output_real_16 = D_16(real_high_freqs).view(-1)\n",
    "                loss_disc_real_16 = criterion(output_real_16, torch.ones_like(output_real_16))\n",
    "                generated_high_freqs_16 = G_16(images_G8)\n",
    "                output_fake_16 = D_16(generated_high_freqs_16.detach()).view(-1)\n",
    "                loss_disc_fake_16 = criterion(output_fake_16, torch.zeros_like(output_fake_16))\n",
    "                loss_disc_16 = (loss_disc_real_16 + loss_disc_fake_16) / 2\n",
    "                loss_disc_16.backward()\n",
    "                opt_D_16.step()\n",
    "\n",
    "                total_d16_loss += loss_disc_16.item()\n",
    "\n",
    "                # Train Generator for 16x16 images\n",
    "                opt_G_16.zero_grad()\n",
    "                \n",
    "                # generated_high_freqs_16_1 = G_16(images_G8)\n",
    "                output_fake_16 = D_16(generated_high_freqs_16).view(-1)\n",
    "                adv_loss_16 = criterion(output_fake_16, torch.ones_like(output_fake_16))\n",
    "                l1_loss_16 = l1_loss(generated_high_freqs_16, real_high_freqs)\n",
    "                loss_gen_16 = adv_loss_16 + l1_loss_16\n",
    "                loss_gen_16.backward()\n",
    "                \n",
    "                opt_G_16.step()\n",
    "\n",
    "                total_g16_loss += loss_gen_16.item()\n",
    "\n",
    "                recon_imgs = images_G8 + generated_high_freqs_16\n",
    "                if i % 100 == 0:\n",
    "                    helpMe.save_generated_images(genH_realH=torch.cat([real_high_freqs, generated_high_freqs_16], dim=0),\n",
    "                                                 recon=torch.cat([images_G8, recon_imgs], dim=0), epoch=epoch, i=i,\n",
    "                                                 path=checkpoint_dir, res='16', a='')\n",
    "                \n",
    "                \n",
    "                \n",
    "                images_G16 = F.interpolate(recon_imgs, scale_factor=2, mode='bilinear').detach()\n",
    "                del images_16, real_high_freqs, generated_high_freqs_16, output_real_16, output_fake_16, loss_disc_real_16, loss_disc_fake_16, adv_loss_16, l1_loss_16, recon_imgs\n",
    "               \n",
    "               \n",
    "                _, real_high_freqs = helpMe.to_gaus(imgs=images)\n",
    "                real_high_freqs = real_high_freqs.to(device)[perm]\n",
    "                \n",
    "                \n",
    "\n",
    "                # Train Discriminator (D_32)\n",
    "                opt_D_32.zero_grad()\n",
    "                output_real_32 = D_32(real_high_freqs).view(-1)\n",
    "                loss_disc_real_32 = criterion(output_real_32, torch.ones_like(output_real_32))\n",
    "                generated_high_freqs_32 = G_32(images_G16)\n",
    "                # print(\"gen\", generated_high_freqs_32.shape)\n",
    "                output_fake_32 = D_32(generated_high_freqs_32.detach()).view(-1)\n",
    "                loss_disc_fake_32 = criterion(output_fake_32, torch.zeros_like(output_fake_32))\n",
    "                loss_disc_32 = (loss_disc_real_32 + loss_disc_fake_32) / 2\n",
    "                loss_disc_32.backward(retain_graph=True)\n",
    "                opt_D_32.step()\n",
    "\n",
    "                total_d32_loss += loss_disc_32.item()\n",
    "\n",
    "                # Train Generator for 32x32 images\n",
    "                opt_G_32.zero_grad()\n",
    "                output_fake_32 = D_32(generated_high_freqs_32).view(-1)\n",
    "                adv_loss_32 = criterion(output_fake_32, torch.ones_like(output_fake_32))\n",
    "                l1_loss_32 = l1_loss(generated_high_freqs_32, real_high_freqs)\n",
    "                loss_gen_32 = adv_loss_32 + l1_loss_32\n",
    "                loss_gen_32.backward()\n",
    "                opt_G_32.step()\n",
    "\n",
    "                total_g32_loss += loss_gen_32.item()\n",
    "\n",
    "                recon_imgs = images_G16 + generated_high_freqs_32\n",
    "                if i % 100 == 0:\n",
    "                    helpMe.save_generated_images(genH_realH=torch.cat([real_high_freqs, generated_high_freqs_32], dim=0),\n",
    "                                                 recon=torch.cat([images_G16, recon_imgs], dim=0), epoch=epoch, i=i,\n",
    "                                                 path=checkpoint_dir, res='32', a='')\n",
    "                    \n",
    "                del images, real_high_freqs, generated_high_freqs_32, output_real_32, output_fake_32, loss_disc_real_32, loss_disc_fake_32, adv_loss_32, l1_loss_32, recon_imgs\n",
    "                \n",
    "                \n",
    "                t.set_description(f'Epoch [{epoch}/{num_epochs}]')\n",
    "                t.set_postfix({\n",
    "                    'D32_loss': f'{loss_disc_32:.3f}',\n",
    "                    'G32_loss': f'{loss_gen_32:.3f}',\n",
    "                    'D16_loss': f'{loss_disc_16:.3f}',\n",
    "                    'G16_loss': f'{loss_gen_16:.3f}',\n",
    "                    'D8_loss': f'{loss_D_8:.3f}',\n",
    "                    'G8_loss': f'{loss_G_8:.3f}'\n",
    "                })\n",
    "\n",
    "                wandb.log({\n",
    "                    'D32_loss': loss_disc_32.item(),\n",
    "                    'G32_loss': loss_gen_32.item(),\n",
    "                    'D16_loss': loss_disc_16.item(),\n",
    "                    'G16_loss': loss_gen_16.item(),\n",
    "                    'D8_loss': loss_D_8.item(),\n",
    "                    'G8_loss': loss_G_8.item()\n",
    "                })\n",
    "                \n",
    "                \n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        avg_d32_loss = total_d32_loss / len(dataloader)\n",
    "        avg_g32_loss = total_g32_loss / len(dataloader)\n",
    "        avg_d16_loss = total_d16_loss / len(dataloader)\n",
    "        avg_g16_loss = total_g16_loss / len(dataloader)\n",
    "        avg_d8_loss = total_d8_loss / (len(dataloader)*5)\n",
    "        avg_g8_loss = total_g8_loss / (len(dataloader)*5)\n",
    "        print(f\"Epoch {epoch}: Loss D32: {avg_d32_loss:.4f}, Loss G32: {avg_g32_loss:.4f}, Loss D16: {avg_d16_loss:.4f}, Loss G16: {avg_g16_loss:.4f}, Loss D8: {avg_d8_loss:.4f}, Loss G8: {avg_g8_loss:.4f}\")\n",
    "\n",
    "        # Save generated images for visualization\n",
    "        # Initialize the LAPGAN model with the save path and device\n",
    "        # save_path = 'path/to/save/images'\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        lapgan_model = LAPGAN(generators, discriminators, checkpoint_dir, device)\n",
    "        lapgan_model.to(device)\n",
    "\n",
    "        # During training, call the forward method with epoch and iteration (batch index)\n",
    "        \n",
    "        fixed_noise = torch.randn(10, noise_dim, device=device)\n",
    "        fixed_labels = torch.arange(0, 10, dtype=torch.long, device=device)\n",
    "        # noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "        lapgan_model(fixed_noise, fixed_labels, epoch, i)\n",
    "\n",
    "        # Save the model\n",
    "        save_model(generators, discriminators, opt_G_32, opt_D_32, opt_G_16, opt_D_16, opt_G_8, opt_D_8, epoch, checkpoint_dir)\n",
    "\n",
    "# Assuming dataset and other parameters are properly defined elsewhere\n",
    "gen32 = Unet.UNetGenerator(in_channels=3, out_channels=3,)\n",
    "disc32 = Unet.Discriminator(in_channels=3, )\n",
    "gen16 = Unet.UNetGenerator(features=[64, 128, 256],in_channels=3, out_channels=3)\n",
    "disc16 = Unet.Discriminator(features=[64, 128, 256],in_channels=3,)\n",
    "gen8 = Unet.Generator_L2()\n",
    "disc8 = Unet.Discriminator_L2()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "generators = (gen32, gen16, gen8)\n",
    "discriminators = (disc32, disc16, disc8)\n",
    "\n",
    "checkpoint_dir = f\"Models/{model_name}3/\"\n",
    "\n",
    "train_gan(generators, discriminators, dataloader, num_epochs=epochs, batch_size=32, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "wandb.finish()  # Finish the wandb run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
